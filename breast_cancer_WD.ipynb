{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the modules\n",
    "* Import dataset from sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the data into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "[[9.029e+00 1.733e+01 5.879e+01 ... 1.750e-01 4.228e-01 1.175e-01]\n",
      " [2.109e+01 2.657e+01 1.427e+02 ... 2.903e-01 4.098e-01 1.284e-01]\n",
      " [9.173e+00 1.386e+01 5.920e+01 ... 5.087e-02 3.282e-01 8.490e-02]\n",
      " ...\n",
      " [1.429e+01 1.682e+01 9.030e+01 ... 3.333e-02 2.458e-01 6.120e-02]\n",
      " [1.398e+01 1.962e+01 9.112e+01 ... 1.827e-01 3.179e-01 1.055e-01]\n",
      " [1.218e+01 2.052e+01 7.722e+01 ... 7.431e-02 2.694e-01 6.878e-02]]\n",
      "TEST\n",
      "[[1.247e+01 1.860e+01 8.109e+01 ... 1.015e-01 3.014e-01 8.750e-02]\n",
      " [1.894e+01 2.131e+01 1.236e+02 ... 1.789e-01 2.551e-01 6.589e-02]\n",
      " [1.546e+01 1.948e+01 1.017e+02 ... 1.514e-01 2.837e-01 8.019e-02]\n",
      " ...\n",
      " [1.152e+01 1.493e+01 7.387e+01 ... 9.608e-02 2.664e-01 7.809e-02]\n",
      " [1.422e+01 2.785e+01 9.255e+01 ... 8.219e-02 1.890e-01 7.796e-02]\n",
      " [2.073e+01 3.112e+01 1.357e+02 ... 1.659e-01 2.868e-01 8.218e-02]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"TRAIN\")\n",
    "print(X_train)\n",
    "print(\"TEST\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalize the features\n",
    "In order for the model to have better performance and avoid bias by features that have larger values\n",
    "Set up data in values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "[[0.06552721 0.25769361 0.07732252 ... 0.60137457 0.52493594 0.52950153]\n",
      " [0.65620256 0.57017247 0.67420686 ... 0.9975945  0.49931007 0.62190573]\n",
      " [0.07257946 0.14034494 0.08023901 ... 0.174811   0.33845851 0.25313666]\n",
      " ...\n",
      " [0.32317939 0.2404464  0.30146536 ... 0.11453608 0.17602996 0.05222109]\n",
      " [0.30799745 0.33513696 0.30729834 ... 0.62783505 0.31815494 0.42777213]\n",
      " [0.21984426 0.36557322 0.20842225 ... 0.25536082 0.22255076 0.11648016]]\n",
      "TEST\n",
      "[[0.23404672 0.30064254 0.23595106 ... 0.34879725 0.2856298  0.27517803]\n",
      " [0.55090847 0.39228948 0.53834116 ... 0.61477663 0.19436231 0.09198033]\n",
      " [0.38047897 0.33040243 0.38255797 ... 0.52027491 0.25073921 0.21320787]\n",
      " ...\n",
      " [0.18752143 0.17653027 0.1845924  ... 0.33017182 0.2166371  0.19540522]\n",
      " [0.31975121 0.61345959 0.31747048 ... 0.28243986 0.06406466 0.19430315]\n",
      " [0.63857192 0.72404464 0.62441315 ... 0.57010309 0.25684999 0.23007799]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# sneak peek data\n",
    "print(\"TRAIN\")\n",
    "print(X_train)\n",
    "print(\"TEST\")\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the MLP (Multi Layer Perceptron) model\n",
    "\n",
    "* The choice of the number of layers, neurons, activation functions, and hyperparameters can affect the performance and generalization of the model. I decided on these values based  on some common practices and heuristics for MLP design, such as:\n",
    "    * Using a sigmoid activation function for the output layer, since this is a binary classification problem.\n",
    "    * Using a sigmoid activation function for the hidden layers, since this is a simple and smooth nonlinear function that can approximate any function.\n",
    "    * Using a binary cross-entropy loss function, since this is a suitable loss for binary classification problems.\n",
    "    * Using an adam optimizer, since this is a popular and efficient gradient-based optimization algorithm that can adapt the learning rate dynamically.\n",
    "    * Using a small number of hidden layers (three) and neurons (16, 8, and 4), since this is a relatively small and low-dimensional dataset (569 samples and 30 features), and a complex model might overfit the data.\n",
    "    * Using a validation split of 0.2, since this is a reasonable proportion of the data to use for evaluating the model during training.\n",
    "    * Using 100 epochs and 32 batch size, since these are typical values that can allow the model to converge without taking too long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation='sigmoid', input_shape=(30,)))\n",
    "model.add(keras.layers.Dense(8, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(4, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 0.6887 - accuracy: 0.6022 - val_loss: 0.6828 - val_accuracy: 0.6228\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.6286 - val_loss: 0.6742 - val_accuracy: 0.6228\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6286 - val_loss: 0.6687 - val_accuracy: 0.6228\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.6286 - val_loss: 0.6647 - val_accuracy: 0.6228\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.6286 - val_loss: 0.6617 - val_accuracy: 0.6228\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6286 - val_loss: 0.6595 - val_accuracy: 0.6228\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6286 - val_loss: 0.6573 - val_accuracy: 0.6228\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6286 - val_loss: 0.6553 - val_accuracy: 0.6228\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6286 - val_loss: 0.6530 - val_accuracy: 0.6228\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6286 - val_loss: 0.6509 - val_accuracy: 0.6228\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6286 - val_loss: 0.6486 - val_accuracy: 0.6228\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6286 - val_loss: 0.6461 - val_accuracy: 0.6228\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6286 - val_loss: 0.6433 - val_accuracy: 0.6228\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6286 - val_loss: 0.6403 - val_accuracy: 0.6228\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6286 - val_loss: 0.6369 - val_accuracy: 0.6228\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6286 - val_loss: 0.6332 - val_accuracy: 0.6228\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6286 - val_loss: 0.6293 - val_accuracy: 0.6228\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6286 - val_loss: 0.6249 - val_accuracy: 0.6228\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6286 - val_loss: 0.6200 - val_accuracy: 0.6228\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6286 - val_loss: 0.6145 - val_accuracy: 0.6228\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6286 - val_loss: 0.6085 - val_accuracy: 0.6228\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.6286 - val_loss: 0.6020 - val_accuracy: 0.6228\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6286 - val_loss: 0.5948 - val_accuracy: 0.6228\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6286 - val_loss: 0.5870 - val_accuracy: 0.6228\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6286 - val_loss: 0.5783 - val_accuracy: 0.6228\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.6286 - val_loss: 0.5692 - val_accuracy: 0.6228\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6330 - val_loss: 0.5593 - val_accuracy: 0.6404\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.6527 - val_loss: 0.5487 - val_accuracy: 0.6930\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.6791 - val_loss: 0.5377 - val_accuracy: 0.7544\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7451 - val_loss: 0.5264 - val_accuracy: 0.7807\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7736 - val_loss: 0.5144 - val_accuracy: 0.7895\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.8154 - val_loss: 0.5019 - val_accuracy: 0.8421\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8637 - val_loss: 0.4894 - val_accuracy: 0.8684\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8769 - val_loss: 0.4761 - val_accuracy: 0.8772\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8835 - val_loss: 0.4630 - val_accuracy: 0.8860\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.8967 - val_loss: 0.4500 - val_accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.9055 - val_loss: 0.4367 - val_accuracy: 0.9386\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.9099 - val_loss: 0.4238 - val_accuracy: 0.9386\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.9099 - val_loss: 0.4113 - val_accuracy: 0.9474\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.9187 - val_loss: 0.3986 - val_accuracy: 0.9474\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.9253 - val_loss: 0.3866 - val_accuracy: 0.9474\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.9297 - val_loss: 0.3749 - val_accuracy: 0.9474\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.9275 - val_loss: 0.3635 - val_accuracy: 0.9474\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.9341 - val_loss: 0.3523 - val_accuracy: 0.9474\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.9341 - val_loss: 0.3419 - val_accuracy: 0.9474\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.9407 - val_loss: 0.3315 - val_accuracy: 0.9474\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.9363 - val_loss: 0.3219 - val_accuracy: 0.9474\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.9363 - val_loss: 0.3129 - val_accuracy: 0.9474\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.9451 - val_loss: 0.3041 - val_accuracy: 0.9649\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.9473 - val_loss: 0.2955 - val_accuracy: 0.9737\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.9473 - val_loss: 0.2870 - val_accuracy: 0.9737\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.9495 - val_loss: 0.2795 - val_accuracy: 0.9649\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.9429 - val_loss: 0.2727 - val_accuracy: 0.9561\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.9495 - val_loss: 0.2654 - val_accuracy: 0.9649\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.9473 - val_loss: 0.2590 - val_accuracy: 0.9737\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.9516 - val_loss: 0.2526 - val_accuracy: 0.9737\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.9538 - val_loss: 0.2468 - val_accuracy: 0.9737\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.9516 - val_loss: 0.2407 - val_accuracy: 0.9649\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.9560 - val_loss: 0.2353 - val_accuracy: 0.9737\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.9560 - val_loss: 0.2299 - val_accuracy: 0.9737\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9495 - val_loss: 0.2250 - val_accuracy: 0.9737\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.9560 - val_loss: 0.2203 - val_accuracy: 0.9737\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9538 - val_loss: 0.2158 - val_accuracy: 0.9737\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9560 - val_loss: 0.2112 - val_accuracy: 0.9649\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9560 - val_loss: 0.2071 - val_accuracy: 0.9737\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9582 - val_loss: 0.2028 - val_accuracy: 0.9737\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9560 - val_loss: 0.1991 - val_accuracy: 0.9737\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9582 - val_loss: 0.1949 - val_accuracy: 0.9737\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9604 - val_loss: 0.1912 - val_accuracy: 0.9737\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9582 - val_loss: 0.1879 - val_accuracy: 0.9737\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9582 - val_loss: 0.1844 - val_accuracy: 0.9737\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9582 - val_loss: 0.1812 - val_accuracy: 0.9737\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2049 - accuracy: 0.9626 - val_loss: 0.1779 - val_accuracy: 0.9737\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9604 - val_loss: 0.1758 - val_accuracy: 0.9737\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9604 - val_loss: 0.1720 - val_accuracy: 0.9737\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9626 - val_loss: 0.1695 - val_accuracy: 0.9737\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9648 - val_loss: 0.1663 - val_accuracy: 0.9737\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9670 - val_loss: 0.1636 - val_accuracy: 0.9649\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9670 - val_loss: 0.1610 - val_accuracy: 0.9649\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9670 - val_loss: 0.1587 - val_accuracy: 0.9649\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9648 - val_loss: 0.1561 - val_accuracy: 0.9737\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9670 - val_loss: 0.1537 - val_accuracy: 0.9649\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9670 - val_loss: 0.1514 - val_accuracy: 0.9737\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1732 - accuracy: 0.9670 - val_loss: 0.1494 - val_accuracy: 0.9649\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9670 - val_loss: 0.1473 - val_accuracy: 0.9649\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9626 - val_loss: 0.1465 - val_accuracy: 0.9737\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9670 - val_loss: 0.1431 - val_accuracy: 0.9737\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9670 - val_loss: 0.1412 - val_accuracy: 0.9737\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9692 - val_loss: 0.1394 - val_accuracy: 0.9649\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9670 - val_loss: 0.1375 - val_accuracy: 0.9825\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9714 - val_loss: 0.1358 - val_accuracy: 0.9649\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9714 - val_loss: 0.1344 - val_accuracy: 0.9649\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9714 - val_loss: 0.1325 - val_accuracy: 0.9825\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9736 - val_loss: 0.1310 - val_accuracy: 0.9825\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9714 - val_loss: 0.1298 - val_accuracy: 0.9649\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9758 - val_loss: 0.1282 - val_accuracy: 0.9737\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9736 - val_loss: 0.1265 - val_accuracy: 0.9825\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9758 - val_loss: 0.1251 - val_accuracy: 0.9737\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9736 - val_loss: 0.1238 - val_accuracy: 0.9825\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9736 - val_loss: 0.1222 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27c031ffdf0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9825\n",
      "Test loss: 0.12219662219285965\n",
      "Test accuracy: 0.9824561476707458\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "Predictions: [[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Predictions:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate the confusion matrix\n",
    "* Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['Benign', 'Malignant'])\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the Precision, which is the proportion of positive predictions that are actually positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision score:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the F1 score, which is the harmonic mean or precision and recall that measures the balance between them\n",
    "* Get the recall score, which os the proportion of positive samples that are correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*----------------------------*\n",
      "Recall:  0.9859154929577465\n",
      "*----------------------------*\n",
      "f1:  0.9859154929577465\n",
      "*----------------------------*\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"*----------------------------*\")\n",
    "print(\"Recall: \", recall)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"*----------------------------*\")\n",
    "print(\"f1: \", f1)\n",
    "print(\"*----------------------------*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions from MLP\n",
    "\n",
    "Based on these results for the confusion matrix, I would conclude that the classification model is very accurate and has high performance on the test set.\n",
    "\n",
    "# Results analysis\n",
    "* Accuracy 0.973 this means that the model predicted correctly 97.37% of the test samples\n",
    "* Precision \n",
    "    * 0.9722 for positive (malignant) calculated by the formula TP/(TP + FP) giving a 97.22% of correctly predicted malignant samples\n",
    "    * 0.9762 for negative (benignant) calculated by the formula TN/(TN + FN) giving a 97.62% of correctly predicted benign samples\n",
    "* Recall \n",
    "    * 0.9859 Proportion of positive samples (malignant) that are correctly determined by the formula TP/(TP + FN) meaning 98.58% correct predictions\n",
    "    * 0.9535 Proportion of negative samples (benign)    that are correctly determined by the formula FN/(FN + TN) meaning 95.35% correct predictions\n",
    "* F1 score: The harmonic mean of precision and recall that measures the balance between them calculated by: 2 * (precision * recall) / (precision + recall)\n",
    "    * positive (malignant): 0.9790 which means there's a high balance between precision and recall for the malignan samples\n",
    "    * negative (benign):    0.9648 which means there's a high balance between precision and recall for the benign   samples\n",
    "\n",
    "* There's a very good overall score for the MLP approach to this dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
