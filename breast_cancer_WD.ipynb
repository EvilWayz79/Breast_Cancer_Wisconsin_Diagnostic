{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the modules\n",
    "* Import dataset from sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the data into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "[[9.029e+00 1.733e+01 5.879e+01 ... 1.750e-01 4.228e-01 1.175e-01]\n",
      " [2.109e+01 2.657e+01 1.427e+02 ... 2.903e-01 4.098e-01 1.284e-01]\n",
      " [9.173e+00 1.386e+01 5.920e+01 ... 5.087e-02 3.282e-01 8.490e-02]\n",
      " ...\n",
      " [1.429e+01 1.682e+01 9.030e+01 ... 3.333e-02 2.458e-01 6.120e-02]\n",
      " [1.398e+01 1.962e+01 9.112e+01 ... 1.827e-01 3.179e-01 1.055e-01]\n",
      " [1.218e+01 2.052e+01 7.722e+01 ... 7.431e-02 2.694e-01 6.878e-02]]\n",
      "TEST\n",
      "[[1.247e+01 1.860e+01 8.109e+01 ... 1.015e-01 3.014e-01 8.750e-02]\n",
      " [1.894e+01 2.131e+01 1.236e+02 ... 1.789e-01 2.551e-01 6.589e-02]\n",
      " [1.546e+01 1.948e+01 1.017e+02 ... 1.514e-01 2.837e-01 8.019e-02]\n",
      " ...\n",
      " [1.152e+01 1.493e+01 7.387e+01 ... 9.608e-02 2.664e-01 7.809e-02]\n",
      " [1.422e+01 2.785e+01 9.255e+01 ... 8.219e-02 1.890e-01 7.796e-02]\n",
      " [2.073e+01 3.112e+01 1.357e+02 ... 1.659e-01 2.868e-01 8.218e-02]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"TRAIN\")\n",
    "print(X_train)\n",
    "print(\"TEST\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalize the features\n",
    "In order for the model to have better performance and avoid bias by features that have larger values\n",
    "Set up data in values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "[[0.06552721 0.25769361 0.07732252 ... 0.60137457 0.52493594 0.52950153]\n",
      " [0.65620256 0.57017247 0.67420686 ... 0.9975945  0.49931007 0.62190573]\n",
      " [0.07257946 0.14034494 0.08023901 ... 0.174811   0.33845851 0.25313666]\n",
      " ...\n",
      " [0.32317939 0.2404464  0.30146536 ... 0.11453608 0.17602996 0.05222109]\n",
      " [0.30799745 0.33513696 0.30729834 ... 0.62783505 0.31815494 0.42777213]\n",
      " [0.21984426 0.36557322 0.20842225 ... 0.25536082 0.22255076 0.11648016]]\n",
      "TEST\n",
      "[[0.23404672 0.30064254 0.23595106 ... 0.34879725 0.2856298  0.27517803]\n",
      " [0.55090847 0.39228948 0.53834116 ... 0.61477663 0.19436231 0.09198033]\n",
      " [0.38047897 0.33040243 0.38255797 ... 0.52027491 0.25073921 0.21320787]\n",
      " ...\n",
      " [0.18752143 0.17653027 0.1845924  ... 0.33017182 0.2166371  0.19540522]\n",
      " [0.31975121 0.61345959 0.31747048 ... 0.28243986 0.06406466 0.19430315]\n",
      " [0.63857192 0.72404464 0.62441315 ... 0.57010309 0.25684999 0.23007799]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# sneak peek data\n",
    "print(\"TRAIN\")\n",
    "print(X_train)\n",
    "print(\"TEST\")\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the MLP (Multi Layer Perceptron) model\n",
    "\n",
    "* The choice of the number of layers, neurons, activation functions, and hyperparameters can affect the performance and generalization of the model. I decided on these values based  on some common practices and heuristics for MLP design, such as:\n",
    "    * Using a sigmoid activation function for the output layer, since this is a binary classification problem.\n",
    "    * Using a sigmoid activation function for the hidden layers, since this is a simple and smooth nonlinear function that can approximate any function.\n",
    "    * Using a binary cross-entropy loss function, since this is a suitable loss for binary classification problems.\n",
    "    * Using an adam optimizer, since this is a popular and efficient gradient-based optimization algorithm that can adapt the learning rate dynamically.\n",
    "    * Using a small number of hidden layers (three) and neurons (16, 8, and 4), since this is a relatively small and low-dimensional dataset (569 samples and 30 features), and a complex model might overfit the data.\n",
    "    * Using a validation split of 0.2, since this is a reasonable proportion of the data to use for evaluating the model during training.\n",
    "    * Using 100 epochs and 32 batch size, since these are typical values that can allow the model to converge without taking too long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation='sigmoid', input_shape=(30,)))\n",
    "model.add(keras.layers.Dense(8, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(4, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 13ms/step - loss: 0.6728 - accuracy: 0.6286 - val_loss: 0.6705 - val_accuracy: 0.6228\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6286 - val_loss: 0.6658 - val_accuracy: 0.6228\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6286 - val_loss: 0.6631 - val_accuracy: 0.6228\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6286 - val_loss: 0.6610 - val_accuracy: 0.6228\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6286 - val_loss: 0.6592 - val_accuracy: 0.6228\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6286 - val_loss: 0.6575 - val_accuracy: 0.6228\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6286 - val_loss: 0.6560 - val_accuracy: 0.6228\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6286 - val_loss: 0.6544 - val_accuracy: 0.6228\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6286 - val_loss: 0.6527 - val_accuracy: 0.6228\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6286 - val_loss: 0.6508 - val_accuracy: 0.6228\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6286 - val_loss: 0.6489 - val_accuracy: 0.6228\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6286 - val_loss: 0.6466 - val_accuracy: 0.6228\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6286 - val_loss: 0.6440 - val_accuracy: 0.6228\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6286 - val_loss: 0.6411 - val_accuracy: 0.6228\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6286 - val_loss: 0.6379 - val_accuracy: 0.6228\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6286 - val_loss: 0.6341 - val_accuracy: 0.6228\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6286 - val_loss: 0.6299 - val_accuracy: 0.6228\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6286 - val_loss: 0.6251 - val_accuracy: 0.6228\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6286 - val_loss: 0.6202 - val_accuracy: 0.6228\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6286 - val_loss: 0.6140 - val_accuracy: 0.6228\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.6286 - val_loss: 0.6071 - val_accuracy: 0.6228\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.6286 - val_loss: 0.5996 - val_accuracy: 0.6228\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6286 - val_loss: 0.5912 - val_accuracy: 0.6228\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6286 - val_loss: 0.5819 - val_accuracy: 0.6228\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.6286 - val_loss: 0.5716 - val_accuracy: 0.6228\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.6286 - val_loss: 0.5605 - val_accuracy: 0.6228\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.6308 - val_loss: 0.5486 - val_accuracy: 0.6316\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.6484 - val_loss: 0.5357 - val_accuracy: 0.6930\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.6945 - val_loss: 0.5225 - val_accuracy: 0.7368\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7363 - val_loss: 0.5090 - val_accuracy: 0.7632\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7714 - val_loss: 0.4953 - val_accuracy: 0.7982\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8066 - val_loss: 0.4812 - val_accuracy: 0.8158\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8484 - val_loss: 0.4675 - val_accuracy: 0.8684\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8703 - val_loss: 0.4536 - val_accuracy: 0.8772\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8791 - val_loss: 0.4400 - val_accuracy: 0.8860\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8879 - val_loss: 0.4266 - val_accuracy: 0.9123\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8923 - val_loss: 0.4136 - val_accuracy: 0.9211\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.9077 - val_loss: 0.4014 - val_accuracy: 0.9386\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.9143 - val_loss: 0.3894 - val_accuracy: 0.9386\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.9209 - val_loss: 0.3776 - val_accuracy: 0.9474\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.9319 - val_loss: 0.3664 - val_accuracy: 0.9474\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.9363 - val_loss: 0.3557 - val_accuracy: 0.9474\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.9363 - val_loss: 0.3455 - val_accuracy: 0.9474\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.9407 - val_loss: 0.3357 - val_accuracy: 0.9474\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.9363 - val_loss: 0.3265 - val_accuracy: 0.9474\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.9363 - val_loss: 0.3179 - val_accuracy: 0.9474\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.9407 - val_loss: 0.3093 - val_accuracy: 0.9474\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.9385 - val_loss: 0.3010 - val_accuracy: 0.9474\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.9429 - val_loss: 0.2936 - val_accuracy: 0.9561\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.9407 - val_loss: 0.2862 - val_accuracy: 0.9474\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.9363 - val_loss: 0.2787 - val_accuracy: 0.9561\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.9451 - val_loss: 0.2720 - val_accuracy: 0.9561\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.9407 - val_loss: 0.2659 - val_accuracy: 0.9561\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.9407 - val_loss: 0.2596 - val_accuracy: 0.9561\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.9516 - val_loss: 0.2545 - val_accuracy: 0.9649\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.9516 - val_loss: 0.2481 - val_accuracy: 0.9561\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.9538 - val_loss: 0.2427 - val_accuracy: 0.9649\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9538 - val_loss: 0.2375 - val_accuracy: 0.9649\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.9538 - val_loss: 0.2324 - val_accuracy: 0.9649\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.9560 - val_loss: 0.2278 - val_accuracy: 0.9649\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.9538 - val_loss: 0.2232 - val_accuracy: 0.9649\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.9560 - val_loss: 0.2186 - val_accuracy: 0.9649\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9516 - val_loss: 0.2152 - val_accuracy: 0.9649\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9560 - val_loss: 0.2102 - val_accuracy: 0.9649\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9560 - val_loss: 0.2061 - val_accuracy: 0.9649\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9582 - val_loss: 0.2022 - val_accuracy: 0.9737\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9560 - val_loss: 0.1987 - val_accuracy: 0.9649\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.9582 - val_loss: 0.1951 - val_accuracy: 0.9649\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9604 - val_loss: 0.1915 - val_accuracy: 0.9649\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9582 - val_loss: 0.1881 - val_accuracy: 0.9649\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9604 - val_loss: 0.1848 - val_accuracy: 0.9737\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9582 - val_loss: 0.1819 - val_accuracy: 0.9737\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2048 - accuracy: 0.9670 - val_loss: 0.1787 - val_accuracy: 0.9737\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.9626 - val_loss: 0.1757 - val_accuracy: 0.9737\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9626 - val_loss: 0.1731 - val_accuracy: 0.9737\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9604 - val_loss: 0.1714 - val_accuracy: 0.9649\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9626 - val_loss: 0.1676 - val_accuracy: 0.9649\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1905 - accuracy: 0.9648 - val_loss: 0.1648 - val_accuracy: 0.9737\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9692 - val_loss: 0.1622 - val_accuracy: 0.9737\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1847 - accuracy: 0.9692 - val_loss: 0.1596 - val_accuracy: 0.9737\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9692 - val_loss: 0.1575 - val_accuracy: 0.9737\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9714 - val_loss: 0.1552 - val_accuracy: 0.9737\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9692 - val_loss: 0.1529 - val_accuracy: 0.9825\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9692 - val_loss: 0.1510 - val_accuracy: 0.9649\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9692 - val_loss: 0.1489 - val_accuracy: 0.9649\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9692 - val_loss: 0.1468 - val_accuracy: 0.9649\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9714 - val_loss: 0.1452 - val_accuracy: 0.9737\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9714 - val_loss: 0.1429 - val_accuracy: 0.9737\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9692 - val_loss: 0.1410 - val_accuracy: 0.9825\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9714 - val_loss: 0.1395 - val_accuracy: 0.9649\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9714 - val_loss: 0.1375 - val_accuracy: 0.9825\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9758 - val_loss: 0.1361 - val_accuracy: 0.9737\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9714 - val_loss: 0.1342 - val_accuracy: 0.9737\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9736 - val_loss: 0.1327 - val_accuracy: 0.9737\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9714 - val_loss: 0.1310 - val_accuracy: 0.9825\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9736 - val_loss: 0.1295 - val_accuracy: 0.9737\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9736 - val_loss: 0.1280 - val_accuracy: 0.9737\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9714 - val_loss: 0.1268 - val_accuracy: 0.9825\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9736 - val_loss: 0.1253 - val_accuracy: 0.9737\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9736 - val_loss: 0.1241 - val_accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b70877c9d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9737\n",
      "Test loss: 0.12409792095422745\n",
      "Test accuracy: 0.9736841917037964\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "Predictions: [[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Predictions:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate the confusion matrix\n",
    "* Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  2]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAG2CAYAAABYlw1sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9fElEQVR4nO3deXRUVbr38d9JQuZUBSJkkIRBZhFQWjGCCjYYaKRB6Fa52IZJFxqQ4eL0KgooxosKNC2CDCY40CgKXKEbvBgBEQGFNrYDpAkCCZIEWsyoGUid9480pSWDqVSFpI7fz1pnLeqcs/d+klXAs5699zmGaZqmAAAAfIBfQwcAAABQWyQuAADAZ5C4AAAAn0HiAgAAfAaJCwAA8BkkLgAAwGeQuAAAAJ9B4gIAAHwGiQsAAPAZJC4AAMBnkLgAAACPtW7dWoZhnHWkpKRIksrLy5WSkqKoqCiFh4drxIgRKigocHscg3cVAQAAT508eVLV1dXOz1988YUGDBigrVu3qm/fvrr33nv1t7/9Tenp6bLb7Zo4caL8/Py0c+dOt8YhcQEAAF43ZcoUbdy4UQcPHlRxcbGaN2+uVatW6Q9/+IMk6cCBA+rcubN27dqla6+9ttb9BtRXwPA+h8Oh48ePKyIiQoZhNHQ4AAA3maapkpISxcXFyc+v/lZrlJeXq7Ky0uN+TNM86/+boKAgBQUFXbBdZWWlXnvtNU2bNk2GYWjfvn2qqqpS//79nfd06tRJCQkJJC5Wdvz4ccXHxzd0GAAAD+Xm5qply5b10nd5ebnatApX/onqX775F4SHh6u0tNTl3BNPPKGZM2desN369etVWFio0aNHS5Ly8/MVGBioyMhIl/uio6OVn5/vVkwkLj4kIiJCknTpnx+SX8iFs13AV7W778uGDgGoN6fNKu2ofsf573l9qKysVP6Jah3d11q2iLpXdYpLHGrV84hyc3Nls9mc53+p2iJJK1as0KBBgxQXF1fn8c+HxMWHnCnX+YUEyS8kuIGjAepHgNGkoUMA6t3FmO4PjzAUHlH3cRyqaWuz2VwSl19y9OhRvffee1q7dq3zXExMjCorK1VYWOhSdSkoKFBMTIxbcbEdGgAAC6o2HR4fdZGWlqYWLVpo8ODBznM9e/ZUkyZNlJGR4TyXlZWlnJwcJSYmutU/FRcAACzIIVMO1X3jcF3aOhwOpaWlKTk5WQEBP6YYdrtd48aN07Rp09SsWTPZbDZNmjRJiYmJbi3MlUhcAACAl7z33nvKycnR2LFjz7o2f/58+fn5acSIEaqoqFBSUpJefPFFt8cgcQEAwIIccqhukz0/tnfXzTffrPM9Hi44OFiLFi3SokWLPIiKxAUAAEuqNk1Ve/CMWU/a1icW5wIAAJ9BxQUAAAtqiMW5FwOJCwAAFuSQqWoLJi5MFQEAAJ9BxQUAAAtiqggAAPgMdhUBAAA0MCouAABYkOM/hyftGyMSFwAALKjaw11FnrStTyQuAABYULVZc3jSvjFijQsAAPAZVFwAALAg1rgAAACf4ZChahketW+MmCoCAAA+g4oLAAAW5DBrDk/aN0YkLgAAWFC1h1NFnrStT0wVAQAAn0HFBQAAC7JqxYXEBQAAC3KYhhymB7uKPGhbn5gqAgAAPoOKCwAAFsRUEQAA8BnV8lO1BxMr1V6MxZtIXAAAsCDTwzUuJmtcAAAAPEPFBQAAC2KNCwAA8BnVpp+qTQ/WuDTSR/4zVQQAAHwGFRcAACzIIUMOD+oTDjXOkguJCwAAFmTVNS5MFQEAAJ9BxQUAAAvyfHEuU0UAAOAiqVnj4sFLFpkqAgAA8AwVFwAALMjh4buK2FUEAAAuGta4AAAAn+GQnyWf48IaFwAA4DOouAAAYEHVpqFq04MH0HnQtj6RuAAAYEHVHi7OrWaqCAAAwDNUXAAAsCCH6SeHB7uKHOwqAgAAFwtTRQAAABfwzTff6M4771RUVJRCQkJ0xRVXaO/evc7rpmnq8ccfV2xsrEJCQtS/f38dPHjQrTFIXAAAsCCHftxZVJfD4eZ43333nXr37q0mTZpo06ZN+uqrr/T888+radOmznvmzp2rhQsXasmSJdqzZ4/CwsKUlJSk8vLyWo/DVBEAABbk+QPo3Gv7P//zP4qPj1daWprzXJs2bZx/Nk1TCxYs0GOPPaahQ4dKkl555RVFR0dr/fr1uuOOO2o1DhUXAABwXsXFxS5HRUXFOe9755139Jvf/EZ//OMf1aJFC1155ZVatmyZ8/rhw4eVn5+v/v37O8/Z7Xb16tVLu3btqnU8JC4AAFjQmXcVeXJIUnx8vOx2u/NITU0953hff/21Fi9erPbt2+vdd9/Vvffeq/vvv18rV66UJOXn50uSoqOjXdpFR0c7r9UGU0UAAFiQQ4YcqvvTb8+0zc3Nlc1mc54PCgo69/0Oh37zm9/o6aefliRdeeWV+uKLL7RkyRIlJyfXOY6fo+ICAIAFeaviYrPZXI7zJS6xsbHq0qWLy7nOnTsrJydHkhQTEyNJKigocLmnoKDAea02SFwAAIDHevfuraysLJdz//rXv9SqVStJNQt1Y2JilJGR4bxeXFysPXv2KDExsdbjMFUEAIAFef4AOvfaTp06Vdddd52efvpp3Xbbbfr444+1dOlSLV26VJJkGIamTJmip556Su3bt1ebNm00Y8YMxcXFadiwYbUeh8QFAAALcpiGHB684dndtldffbXWrVunRx55RLNnz1abNm20YMECjRo1ynnPgw8+qLKyMt1zzz0qLCxUnz59tHnzZgUHB9d6HBIXAADgFbfccotuueWW8143DEOzZ8/W7Nmz6zwGiQsAABbk8HCqyJOH19UnEhcAACzI87dDN87EpXFGBQAAcA5UXAAAsKBqGar24AF0nrStTyQuAABYEFNFAAAADYyKCwAAFlQtz6Z7qr0XileRuAAAYEFWnSoicQEAwIJ++qLEurZvjBpnVAAAAOdAxQUAAAsyZcjhwRoXk+3QAADgYmGqCAAAoIFRcQEAwIIcpiGHWffpHk/a1icSFwAALKjaw7dDe9K2PjXOqAAAAM6BigsAABbEVBEAAPAZDvnJ4cHEiidt61PjjAoAAOAcqLgAAGBB1aahag+mezxpW59IXAAAsCDWuAAAAJ9hevh2aJMn5wIAAHiGigsAABZULUPVHrwo0ZO29YnEBQAAC3KYnq1TcZheDMaLmCoCAAA+g4pLHbRu3VpTpkzRlClTGjoUeFnTDfm6ZM1xfXdzc/37znhJkm3rvxWx65SCjnwv/3KHDi3uJkcYf3Xgu25PyVPvgYVqeVm5Ksv99NW+ML2c2lLHvg5u6NDgRQ4PF+d60rY+Nc6o6mj06NEyDMN5REVFaeDAgfrnP//p1XE++eQT3XPPPV7tEw0v6Osy2bf+WxXxIS7n/Soc+v4Km74bEtNAkQHedUWvUm1Y2VxTh3XSI6PaKyDA1JzXDioopLqhQ4MXOWR4fDRGlkpcJGngwIHKy8tTXl6eMjIyFBAQoFtuucWrYzRv3lyhoaFe7RMNyyivVsziIyoYm6DqMH+Xa4UDW+i7ITEqbxfWQNEB3vXYXe215a1LdPRfITq8P1TP/3drRbesVPsrvm/o0IBfZLnEJSgoSDExMYqJiVGPHj308MMPKzc3VydPnpQk5ebm6rbbblNkZKSaNWumoUOH6siRI872o0eP1rBhw/Tcc88pNjZWUVFRSklJUVVVlfOe1q1ba8GCBc7PBw4cUJ8+fRQcHKwuXbrovffek2EYWr9+vSTpyJEjMgxDa9euVb9+/RQaGqru3btr165dF+NXglposTJXZT3s+qGrraFDAS660IiaSktJIVOgVnLmybmeHI2R5RKXnyotLdVrr72mdu3aKSoqSlVVVUpKSlJERIR27NihnTt3Kjw8XAMHDlRlZaWz3datW3Xo0CFt3bpVK1euVHp6utLT0885RnV1tYYNG6bQ0FDt2bNHS5cu1aOPPnrOex999FFNnz5dmZmZ6tChg0aOHKnTp0/Xx48ON4TvPqWgo9/r2z/GNXQowEVnGKYmzDymLz8J09F/hfxyA/iMM2tcPDkaI8ul1xs3blR4eLgkqaysTLGxsdq4caP8/Py0atUqORwOLV++XIZRk0mmpaUpMjJS27Zt08033yxJatq0qV544QX5+/urU6dOGjx4sDIyMnT33XefNd6WLVt06NAhbdu2TTExNWsg5syZowEDBpx17/Tp0zV48GBJ0qxZs3T55ZcrOztbnTp1OufPUlFRoYqKCufn4uJiD34zOJeAbyvV/LVj+ubBdjIDG+dfUqA+pTyVo9YdftB/j+jY0KEAtWK5xKVfv35avHixJOm7777Tiy++qEGDBunjjz/WZ599puzsbEVERLi0KS8v16FDh5yfL7/8cvn7/7jOITY2Vp9//vk5x8vKylJ8fLwzaZGka6655pz3duvWzaVPSTpx4sR5E5fU1FTNmjXrQj8uPBR05HsFFJ9WwuMHnOcMhxSSVarI904q++UrJb/GWS4FPHXf7Bz1+m2Rpv+xo/6dH9jQ4cDLHPLwXUWNdHGu5RKXsLAwtWvXzvl5+fLlstvtWrZsmUpLS9WzZ0+9/vrrZ7Vr3ry5889NmjRxuWYYhhwOh8ex/bTfMxWfC/X7yCOPaNq0ac7PxcXFio+P9zgO/Oj7LhE6+nRnl3PRy46qMjZY390STdICizJ13+xcXTewUA/e1kEFuUENHRDqgenhziCTxKVhGIYhPz8//fDDD7rqqqv0xhtvqEWLFrLZvLMIs2PHjsrNzVVBQYGio6Ml1WyX9oagoCAFBfEPSn0yQ/xV2dJ1Xt8R5Kfq8B/P+xdWyb+oSk0KaqbtAo+VyxHsp9NRgXKEW/6vECwo5alc9Rt6SrPGX6YfyvzVtHnN5oOyYn9VVjBlahW8HdpHVFRUKD8/X1LNVNELL7yg0tJSDRkyRNdcc42effZZDR06VLNnz1bLli119OhRrV27Vg8++KBatmzp9ngDBgzQZZddpuTkZM2dO1clJSV67LHHJP1YVYFvs79/UlHr852f4+f8S5KUf3crlVwf1VBhAXU25K6aXZbPrvmXy/nnp7XSlrcuaYiQgFqzXOKyefNm5/qRiIgIderUSWvWrFHfvn0lSR988IEeeughDR8+XCUlJbr00kv129/+ts4VGH9/f61fv17jx4/X1VdfrbZt2+rZZ5/VkCFDFBzMUyh90Tf/r4PL51PD43RqODuOYB0DE3o2dAi4CKz65FzDNM1G+hol37Vz50716dNH2dnZuuyyy7zWb3Fxsex2u+KXPi6/EJIiWFOHsd590jXQmJw2q7T19NsqKiry2pKFnzvzf8XQ/xurJmF1X3RdVVap/7355XqNtS4sV3FpCOvWrVN4eLjat2+v7OxsTZ48Wb179/Zq0gIAAEhcvKKkpEQPPfSQcnJydMkll6h///56/vnnGzosAMCvmKfvG2I7tIXddddduuuuuxo6DAAAnKy6q6hxrrwBAAA4BxIXAAAs6EzFxZPDHTNnzpRhGC7HT58MX15erpSUFEVFRSk8PFwjRoxQQUGB2z8XiQsAABZ0sRMXqeaVOXl5ec7jww8/dF6bOnWqNmzYoDVr1mj79u06fvy4hg8f7vYYrHEBAABeERAQ4PLuvjOKioq0YsUKrVq1SjfddJOkmpccd+7cWbt379a1115b6zGouAAAYEHeqrgUFxe7HBUVFecd8+DBg4qLi1Pbtm01atQo5eTkSJL27dunqqoq9e/f33lvp06dlJCQoF27drn1c5G4AABgQaZ+3BJdl+PM02nj4+Nlt9udR2pq6jnH69Wrl9LT07V582YtXrxYhw8f1vXXX6+SkhLl5+crMDBQkZGRLm2io6Odr+mpLaaKAACwIG9th87NzXV5cu75Xv47aNAg55+7deumXr16qVWrVnrzzTcVEhJyzjZ1QcUFAACcl81mcznOl7j8XGRkpDp06KDs7GzFxMSosrJShYWFLvcUFBScc03MhZC4AABgQQ2xq+inSktLdejQIcXGxqpnz55q0qSJMjIynNezsrKUk5OjxMREt/plqggAAAu62E/OnT59uoYMGaJWrVrp+PHjeuKJJ+Tv76+RI0fKbrdr3LhxmjZtmpo1ayabzaZJkyYpMTHRrR1FEokLAADwgmPHjmnkyJH69ttv1bx5c/Xp00e7d+9W8+bNJUnz58+Xn5+fRowYoYqKCiUlJenFF190exwSFwAALOhiV1xWr159wevBwcFatGiRFi1aVOeYJBIXAAAsyTQNmR4kLp60rU8szgUAAD6DigsAABZ05kFynrRvjEhcAACwoIu9xuViYaoIAAD4DCouAABYkFUX55K4AABgQVadKiJxAQDAgqxacWGNCwAA8BlUXAAAsCDTw6mixlpxIXEBAMCCTEmm6Vn7xoipIgAA4DOouAAAYEEOGTJ4ci4AAPAF7CoCAABoYFRcAACwIIdpyOABdAAAwBeYpoe7ihrptiKmigAAgM+g4gIAgAVZdXEuiQsAABZE4gIAAHyGVRfnssYFAAD4DCouAABYkFV3FZG4AABgQTWJiydrXLwYjBcxVQQAAHwGFRcAACyIXUUAAMBnmP85PGnfGDFVBAAAfAYVFwAALIipIgAA4DssOldE4gIAgBV5WHFRI624sMYFAAD4DCouAABYEE/OBQAAPsOqi3OZKgIAAD6DigsAAFZkGp4tsG2kFRcSFwAALMiqa1yYKgIAAD6DigsAAFb0a34A3TvvvFPrDn//+9/XORgAAOAdVt1VVKvEZdiwYbXqzDAMVVdXexIPAADAedUqcXE4HPUdBwAA8LZGOt3jCY/WuJSXlys4ONhbsQAAAC+x6lSR27uKqqur9eSTT+rSSy9VeHi4vv76a0nSjBkztGLFCq8HCAAA6sD0wlFHzzzzjAzD0JQpU5znysvLlZKSoqioKIWHh2vEiBEqKChwu2+3E5c5c+YoPT1dc+fOVWBgoPN8165dtXz5crcDAAAA1vHJJ5/opZdeUrdu3VzOT506VRs2bNCaNWu0fft2HT9+XMOHD3e7f7cTl1deeUVLly7VqFGj5O/v7zzfvXt3HThwwO0AAABAfTC8cLintLRUo0aN0rJly9S0aVPn+aKiIq1YsULz5s3TTTfdpJ49eyotLU0fffSRdu/e7dYYbicu33zzjdq1a3fWeYfDoaqqKne7AwAA9cFLU0XFxcUuR0VFxXmHTElJ0eDBg9W/f3+X8/v27VNVVZXL+U6dOikhIUG7du1y68dyO3Hp0qWLduzYcdb5t956S1deeaW73QEAgEYsPj5edrvdeaSmpp7zvtWrV+sf//jHOa/n5+crMDBQkZGRLuejo6OVn5/vVjxu7yp6/PHHlZycrG+++UYOh0Nr165VVlaWXnnlFW3cuNHd7gAAQH3w0pNzc3NzZbPZnKeDgoLOujU3N1eTJ0/Wli1b6n23sdsVl6FDh2rDhg167733FBYWpscff1z79+/Xhg0bNGDAgPqIEQAAuOvM26E9OSTZbDaX41yJy759+3TixAldddVVCggIUEBAgLZv366FCxcqICBA0dHRqqysVGFhoUu7goICxcTEuPVj1ek5Ltdff722bNlSl6YAAMBifvvb3+rzzz93OTdmzBh16tRJDz30kOLj49WkSRNlZGRoxIgRkqSsrCzl5OQoMTHRrbHq/AC6vXv3av/+/ZJq1r307Nmzrl0BAAAvM82aw5P2tRUREaGuXbu6nAsLC1NUVJTz/Lhx4zRt2jQ1a9ZMNptNkyZNUmJioq699lq34nI7cTl27JhGjhypnTt3OhfZFBYW6rrrrtPq1avVsmVLd7sEAADe1sjeDj1//nz5+flpxIgRqqioUFJSkl588UW3+3F7jcv48eNVVVWl/fv369SpUzp16pT2798vh8Oh8ePHux0AAACwnm3btmnBggXOz8HBwVq0aJFOnTqlsrIyrV271u31LVIdKi7bt2/XRx99pI4dOzrPdezYUX/5y190/fXXux0AAACoBz9ZYFvn9o2Q24lLfHz8OR80V11drbi4OK8EBQAAPGOYNYcn7Rsjt6eKnn32WU2aNEl79+51ntu7d68mT56s5557zqvBAQCAOmrAlyzWp1pVXJo2bSrD+LFkVFZWpl69eikgoKb56dOnFRAQoLFjx2rYsGH1EigAAECtEpefLq4BAAA+4Ne8xiU5Obm+4wAAAN7UyLZDe0udH0AnSeXl5aqsrHQ599P3GQAAAHiT24tzy8rKNHHiRLVo0UJhYWFq2rSpywEAABoBiy7OdTtxefDBB/X+++9r8eLFCgoK0vLlyzVr1izFxcXplVdeqY8YAQCAuyyauLg9VbRhwwa98sor6tu3r8aMGaPrr79e7dq1U6tWrfT6669r1KhR9REnAACA+xWXU6dOqW3btpJq1rOcOnVKktSnTx998MEH3o0OAADUzZldRZ4cjZDbiUvbtm11+PBhSVKnTp305ptvSqqpxJx56SIAAGhYZ56c68nRGLmduIwZM0afffaZJOnhhx/WokWLFBwcrKlTp+qBBx7weoAAAABnuL3GZerUqc4/9+/fXwcOHNC+ffvUrl07devWzavBAQCAOuI5LufWqlUrtWrVyhuxAAAAXFCtEpeFCxfWusP777+/zsEAAADvMOTh26G9Fol31SpxmT9/fq06MwyDxAUAANSbWiUuZ3YRoXG47J7PFGA0aegwgHqx+XhmQ4cA1JviEoeadrhIg/2aX7IIAAB8jEUX57q9HRoAAKChUHEBAMCKLFpxIXEBAMCCPH36rWWenAsAANBQ6pS47NixQ3feeacSExP1zTffSJJeffVVffjhh14NDgAA1JHphaMRcjtxefvtt5WUlKSQkBB9+umnqqiokCQVFRXp6aef9nqAAACgDkhcajz11FNasmSJli1bpiZNfnyWSO/evfWPf/zDq8EBAAD8lNuLc7OysnTDDTecdd5ut6uwsNAbMQEAAA+xOPc/YmJilJ2dfdb5Dz/8UG3btvVKUAAAwENnnpzrydEIuZ243H333Zo8ebL27NkjwzB0/Phxvf7665o+fbruvffe+ogRAAC4y6JrXNyeKnr44YflcDj029/+Vt9//71uuOEGBQUFafr06Zo0aVJ9xAgAACCpDomLYRh69NFH9cADDyg7O1ulpaXq0qWLwsPD6yM+AABQB1Zd41LnJ+cGBgaqS5cu3owFAAB4C4/8r9GvXz8ZxvkX7Lz//vseBQQAAHA+bicuPXr0cPlcVVWlzMxMffHFF0pOTvZWXAAAwBMeThVZpuIyf/78c56fOXOmSktLPQ4IAAB4gUWnirz2ksU777xTL7/8sre6AwAAOEudF+f+3K5duxQcHOyt7gAAgCcsWnFxO3EZPny4y2fTNJWXl6e9e/dqxowZXgsMAADUHduh/8Nut7t89vPzU8eOHTV79mzdfPPNXgsMAADg59xKXKqrqzVmzBhdccUVatq0aX3FBAAAcE5uLc719/fXzTffzFugAQBo7Cz6riK3dxV17dpVX3/9dX3EAgAAvOTMGhdPjsbI7cTlqaee0vTp07Vx40bl5eWpuLjY5QAAAL8+ixcvVrdu3WSz2WSz2ZSYmKhNmzY5r5eXlyslJUVRUVEKDw/XiBEjVFBQ4PY4tU5cZs+erbKyMv3ud7/TZ599pt///vdq2bKlmjZtqqZNmyoyMpJ1LwAANCYXcZqoZcuWeuaZZ7Rv3z7t3btXN910k4YOHaovv/xSkjR16lRt2LBBa9as0fbt23X8+PGzdirXRq0X586aNUsTJkzQ1q1b3R4EAABcZBf5OS5Dhgxx+TxnzhwtXrxYu3fvVsuWLbVixQqtWrVKN910kyQpLS1NnTt31u7du3XttdfWepxaJy6mWfMT3HjjjbXuHAAA+LafLwMJCgpSUFDQBdtUV1drzZo1KisrU2Jiovbt26eqqir179/feU+nTp2UkJCgXbt2uZW4uLXG5UJvhQYAAI2HtxbnxsfHy263O4/U1NTzjvn5558rPDxcQUFBmjBhgtatW6cuXbooPz9fgYGBioyMdLk/Ojpa+fn5bv1cbj3HpUOHDr+YvJw6dcqtAAAAQD3w0lRRbm6ubDab8/SFqi0dO3ZUZmamioqK9NZbbyk5OVnbt2/3IIizuZW4zJo166wn5wIAAOs6s0uoNgIDA9WuXTtJUs+ePfXJJ5/oz3/+s26//XZVVlaqsLDQpepSUFCgmJgYt+JxK3G544471KJFC7cGAAAAF19jeFeRw+FQRUWFevbsqSZNmigjI0MjRoyQJGVlZSknJ0eJiYlu9VnrxIX1LQAA+JCLvKvokUce0aBBg5SQkKCSkhKtWrVK27Zt07vvviu73a5x48Zp2rRpatasmWw2myZNmqTExES3FuZKddhVBAAA8HMnTpzQXXfdpby8PNntdnXr1k3vvvuuBgwYIEmaP3++/Pz8NGLECFVUVCgpKUkvvvii2+PUOnFxOBxudw4AABrIRa64rFix4oLXg4ODtWjRIi1atMiDoNxc4wIAAHxDY1jjUh9IXAAAsKKLXHG5WNx+ySIAAEBDoeICAIAVWbTiQuICAIAFWXWNC1NFAADAZ1BxAQDAipgqAgAAvoKpIgAAgAZGxQUAACtiqggAAPgMiyYuTBUBAACfQcUFAAALMv5zeNK+MSJxAQDAiiw6VUTiAgCABbEdGgAAoIFRcQEAwIqYKgIAAD6lkSYfnmCqCAAA+AwqLgAAWJBVF+eSuAAAYEUWXePCVBEAAPAZVFwAALAgpooAAIDvYKoIAACgYVFxAQDAgpgqAgAAvsOiU0UkLgAAWJFFExfWuAAAAJ9BxQUAAAtijQsAAPAdTBUBAAA0LCouAABYkGGaMsy6l008aVufSFwAALAipooAAAAaFhUXAAAsiF1FAADAdzBVBAAA0LCouAAAYEFMFQEAAN9h0akiEhcAACzIqhUX1rgAAACfQcUFAAArsuhUERUXAAAs6sx0UV0Od6Wmpurqq69WRESEWrRooWHDhikrK8vlnvLycqWkpCgqKkrh4eEaMWKECgoK3BqHxAUAAHhs+/btSklJ0e7du7VlyxZVVVXp5ptvVllZmfOeqVOnasOGDVqzZo22b9+u48ePa/jw4W6Nw1QRAABWZJo1hyft3bB582aXz+np6WrRooX27dunG264QUVFRVqxYoVWrVqlm266SZKUlpamzp07a/fu3br22mtrNQ4VFwAALMiTaaKfThcVFxe7HBUVFbUav6ioSJLUrFkzSdK+fftUVVWl/v37O+/p1KmTEhIStGvXrlr/XCQuAADgvOLj42W3251HamrqL7ZxOByaMmWKevfura5du0qS8vPzFRgYqMjISJd7o6OjlZ+fX+t4mCoCAMCKvLSrKDc3VzabzXk6KCjoF5umpKToiy++0IcffuhBAOdG4gIAgAUZjprDk/aSZLPZXBKXXzJx4kRt3LhRH3zwgVq2bOk8HxMTo8rKShUWFrpUXQoKChQTE1Pr/pkqAgAAHjNNUxMnTtS6dev0/vvvq02bNi7Xe/bsqSZNmigjI8N5LisrSzk5OUpMTKz1OJapuBw5ckRt2rTRp59+qh49emjbtm3q16+fvvvuu7Pm04Bf0rVXqf5430m1v+J7RcWc1syxrbVrs72hwwLq5K5ruqjgWOBZ54ckn9TE1G9UWW5o6aw4bXunqaoqDPXsW6JJqcfUtPnpBogWXnORH0CXkpKiVatW6X//938VERHhXLdit9sVEhIiu92ucePGadq0aWrWrJlsNpsmTZqkxMTEWu8okhq44jJ69GgZhqEJEyacdS0lJUWGYWj06NF16vu6665TXl6e7PbG959Neno6yVQjFxzq0NdfBuuF/9fyl28GGrmFm7L018wvnEfq6mxJ0vVDanZ9LJl5qXZvseuxl47oubXZOlXQRLPHtW7AiOEN3tpVVFuLFy9WUVGR+vbtq9jYWOfxxhtvOO+ZP3++brnlFo0YMUI33HCDYmJitHbtWrfGafCKS3x8vFavXq358+crJCREUs2T9VatWqWEhIQ69xsYGOjWnBnwU3u32rR3a+3ndIHGLDKq2uXzGy/YFdu6Qt0SS1VW7Kd3/9pMDy86qh59SiVJ0+bl6O4bO2v/vlB17vl9Q4QMb7jIz3Exa3F/cHCwFi1apEWLFtU1qoZf43LVVVcpPj7eJeNau3atEhISdOWVVzrPbd68WX369FFkZKSioqJ0yy236NChQ+ftd9u2bTIMQ4WFhc5zy5YtU3x8vEJDQ3Xrrbdq3rx5LpWPmTNnqkePHnr11VfVunVr2e123XHHHSopKal1HEeOHJFhGFq7dq369eun0NBQde/e3blHfdu2bRozZoyKiopkGIYMw9DMmTM9+A0CQO1VVRp6/+2mSrrjWxmGdPCfoTpd5acrry913pPQvkItLq3U/n1hDRgpcG4NnrhI0tixY5WWlub8/PLLL2vMmDEu95SVlWnatGnau3evMjIy5Ofnp1tvvVUOR+2WTO/cuVMTJkzQ5MmTlZmZqQEDBmjOnDln3Xfo0CGtX79eGzdu1MaNG7V9+3Y988wzbsfx6KOPavr06crMzFSHDh00cuRInT59Wtddd50WLFggm82mvLw85eXlafr06eeMuaKi4qwH/wCAJz7abFdpsb9uvu2UJOnUiQA1CXQo3O5alYlsXqVTJxq8KA8PXOypooulUXwr77zzTj3yyCM6evSopJokY/Xq1dq2bZvznhEjRri0efnll9W8eXN99dVXzofbXMhf/vIXDRo0yJkkdOjQQR999JE2btzocp/D4VB6eroiIiIkSX/605+UkZHhTHJqG8f06dM1ePBgSdKsWbN0+eWXKzs7W506dZLdbpdhGL84lZWamqpZs2b94s8GALX17l+b6ep+xYqKYeGt5fF26PrTvHlzDR48WOnp6UpLS9PgwYN1ySWXuNxz8OBBjRw5Um3btpXNZlPr1q0lSTk5ObUaIysrS9dcc43LuZ9/lqTWrVs7kxZJio2N1YkTJ9yOo1u3bi59SHLppzYeeeQRFRUVOY/c3Fy32gPATxUca6JPd0Ro4H996zzXrMVpVVX6qbTI3+XewpNN1KwFyQ0an0ZRcZFqposmTpwoSedctDNkyBC1atVKy5YtU1xcnBwOh7p27arKykqvxtGkSROXz4ZhuEwD1TaOn/ZjGIYk1Xpa64ygoKBaPaEQAGrj/1ZHKfKS0+rV/8dp5/bdvldAE4c+/TBc1w+u2WWUmx2kE98EqnPPsvN1BR/g6XQPU0W/YODAgaqsrJRhGEpKSnK59u233yorK0vLli3T9ddfL0luP0a4Y8eO+uSTT1zO/fzzL/FGHFLNjqfq6upfvhENJji0WnFtfkxGY+Ir1fbyH1RS6K+T35z9PAygsXM4pP97o5n6//GU/H/yL3+YzaGkkae0dOalioisVlhEtRY92lKde5axo8jXXeRdRRdLo0lc/P39tX//fueff6pp06aKiorS0qVLFRsbq5ycHD388MNu9T9p0iTdcMMNmjdvnoYMGaL3339fmzZtclZDasMbcUg101GlpaXKyMhQ9+7dFRoaqtDQULf7Qf3p0P0HPfv2j7vFJsw6Lkn6vzea6vmpdd+mDzSUTz+I0IlvApV0x6mzrk2Y+Y38DFNP3t1aVRWGftO3RBNTjzVAlMAvazSJi6TzvgvBz89Pq1ev1v3336+uXbuqY8eOWrhwofr27Vvrvnv37q0lS5Zo1qxZeuyxx5SUlKSpU6fqhRdeqHUf3ohDqnk43oQJE3T77bfr22+/1RNPPMGW6Ebmn7vClRTXvaHDALymZ98SvXs885zXAoNNTUz9RhNTv7m4QaFeWXWqyDBr88QYi7r77rt14MAB7dixo6FDqZXi4mLZ7Xb11VAFGE1+uQHgg873nytgBcUlDjXt8LWKiorcenGhW2P85/+KxIGzFdAkuM79nK4q167Nj9drrHXRqCou9e25557TgAEDFBYWpk2bNmnlypV68cUXGzosAABQS7+qxOXjjz/W3LlzVVJSorZt22rhwoUaP358Q4cFAIDXWXWq6FeVuLz55psNHQIAABeHw6w5PGnfCP2qEhcAAH41eHIuAABAw6LiAgCABRnycI2L1yLxLhIXAACsyKJPzmWqCAAA+AwqLgAAWBDboQEAgO9gVxEAAEDDouICAIAFGaYpw4MFtp60rU8kLgAAWJHjP4cn7RshpooAAIDPoOICAIAFMVUEAAB8h0V3FZG4AABgRTw5FwAAoGFRcQEAwIJ4ci4AAPAdTBUBAAA0LCouAABYkOGoOTxp3xiRuAAAYEVMFQEAADQsKi4AAFgRD6ADAAC+wqqP/GeqCAAA+AwqLgAAWJFFF+eSuAAAYEWmJE+2NDfOvIXEBQAAK2KNCwAAQAOj4gIAgBWZ8nCNi9ci8SoSFwAArMiii3OZKgIAAB774IMPNGTIEMXFxckwDK1fv97lummaevzxxxUbG6uQkBD1799fBw8edHscEhcAAKzI4YXDDWVlZerevbsWLVp0zutz587VwoULtWTJEu3Zs0dhYWFKSkpSeXm5W+MwVQQAgAVd7F1FgwYN0qBBg855zTRNLViwQI899piGDh0qSXrllVcUHR2t9evX64477qj1OFRcAABAvTp8+LDy8/PVv39/5zm73a5evXpp165dbvVFxQUAACvy0uLc4uJil9NBQUEKCgpyq6v8/HxJUnR0tMv56Oho57XaouICAIAVnUlcPDkkxcfHy263O4/U1NQG/bGouAAAgPPKzc2VzWZzfna32iJJMTExkqSCggLFxsY6zxcUFKhHjx5u9UXFBQAAK/JSxcVms7kcdUlc2rRpo5iYGGVkZDjPFRcXa8+ePUpMTHSrLyouAABYkUOS4WF7N5SWlio7O9v5+fDhw8rMzFSzZs2UkJCgKVOm6KmnnlL79u3Vpk0bzZgxQ3FxcRo2bJhb45C4AABgQRd7O/TevXvVr18/5+dp06ZJkpKTk5Wenq4HH3xQZWVluueee1RYWKg+ffpo8+bNCg4OdmscEhcAAOCxvn37yrxAsmMYhmbPnq3Zs2d7NA6JCwAAVmTRdxWRuAAAYEUOUzI8SD4cjTNxYVcRAADwGVRcAACwIqaKAACA7/AwcVHjTFyYKgIAAD6DigsAAFbEVBEAAPAZDlMeTfewqwgAAMAzVFwAALAi01FzeNK+ESJxAQDAiljjAgAAfAZrXAAAABoWFRcAAKyIqSIAAOAzTHmYuHgtEq9iqggAAPgMKi4AAFgRU0UAAMBnOBySPHgWi6NxPseFqSIAAOAzqLgAAGBFTBUBAACfYdHEhakiAADgM6i4AABgRRZ95D+JCwAAFmSaDpkevOHZk7b1icQFAAArMk3PqiascQEAAPAMFRcAAKzI9HCNSyOtuJC4AABgRQ6HZHiwTqWRrnFhqggAAPgMKi4AAFgRU0UAAMBXmA6HTA+mihrrdmimigAAgM+g4gIAgBUxVQQAAHyGw5QM6yUuTBUBAACfQcUFAAArMk1JnjzHpXFWXEhcAACwINNhyvRgqsgkcQEAABeN6ZBnFRe2QwMAAHiEigsAABbEVBEAAPAdFp0qInHxIWey39Oq8uiZQkBjVlzSOP+xBLyhuLTm+30xqhme/l9xWlXeC8aLSFx8SElJiSTpQ/29gSMB6k/TDg0dAVD/SkpKZLfb66XvwMBAxcTE6MN8z/+viImJUWBgoBei8h7DbKyTWDiLw+HQ8ePHFRERIcMwGjqcX4Xi4mLFx8crNzdXNputocMBvIrv98VnmqZKSkoUFxcnP7/62x9TXl6uyspKj/sJDAxUcHCwFyLyHiouPsTPz08tW7Zs6DB+lWw2G/+ww7L4fl9c9VVp+ang4OBGl3B4C9uhAQCAzyBxAQAAPoPEBbiAoKAgPfHEEwoKCmroUACv4/sNX8TiXAAA4DOouAAAAJ9B4gIAAHwGiQsAAPAZJC6AG1q3bq0FCxY0dBjAWY4cOSLDMJSZmSlJ2rZtmwzDUGFhYYPGBXgbiQssYfTo0TIMw3lERUVp4MCB+uc//+nVcT755BPdc889Xu0Tv15nvrcTJkw461pKSooMw9Do0aPr1Pd1112nvLy8i/KwM3elp6crMjKyocOAjyJxgWUMHDhQeXl5ysvLU0ZGhgICAnTLLbd4dYzmzZsrNDTUq33i1y0+Pl6rV6/WDz/84DxXXl6uVatWKSEhoc79nnlfDa8HgdWQuMAygoKCFBMTo5iYGPXo0UMPP/ywcnNzdfLkSUlSbm6ubrvtNkVGRqpZs2YaOnSojhw54mw/evRoDRs2TM8995xiY2MVFRWllJQUVVX9+IbUn08VHThwQH369FFwcLC6dOmi9957T4ZhaP369ZJ+LN+vXbtW/fr1U2hoqLp3765du3ZdjF8JfMBVV12l+Ph4rV271nlu7dq1SkhI0JVXXuk8t3nzZvXp00eRkZGKiorSLbfcokOHDp2333NNFS1btkzx8fEKDQ3Vrbfeqnnz5rlUPmbOnKkePXro1VdfVevWrWW323XHHXc4X/Bamzh+6Tu/bds2jRkzRkVFRc4K6cyZMz34DeLXhsQFllRaWqrXXntN7dq1U1RUlKqqqpSUlKSIiAjt2LFDO3fuVHh4uAYOHOjyIrKtW7fq0KFD2rp1q1auXKn09HSlp6efc4zq6moNGzZMoaGh2rNnj5YuXapHH330nPc++uijmj59ujIzM9WhQweNHDlSp0+fro8fHT5o7NixSktLc35++eWXNWbMGJd7ysrKNG3aNO3du1cZGRny8/PTrbfeKofDUasxdu7cqQkTJmjy5MnKzMzUgAEDNGfOnLPuO3TokNavX6+NGzdq48aN2r59u5555hm34zjfd/66667TggULZLPZnBXS6dOnu/Prwq+dCVhAcnKy6e/vb4aFhZlhYWGmJDM2Ntbct2+faZqm+eqrr5odO3Y0HQ6Hs01FRYUZEhJivvvuu84+WrVqZZ4+fdp5zx//+Efz9ttvd35u1aqVOX/+fNM0TXPTpk1mQECAmZeX57y+ZcsWU5K5bt060zRN8/Dhw6Ykc/ny5c57vvzyS1OSuX//fq//HuBbkpOTzaFDh5onTpwwg4KCzCNHjphHjhwxg4ODzZMnT5pDhw41k5OTz9n25MmTpiTz888/N03zx+/ap59+apqmaW7dutWUZH733XemaZrm7bffbg4ePNilj1GjRpl2u935+YknnjBDQ0PN4uJi57kHHnjA7NWr13l/hvPFcaHvfFpamsu4gDuouMAy+vXrp8zMTGVmZurjjz9WUlKSBg0apKNHj+qzzz5Tdna2IiIiFB4ervDwcDVr1kzl5eUuZe7LL79c/v7+zs+xsbE6ceLEOcfLyspSfHy8YmJinOeuueaac97brVs3lz4lnbdf/Po0b95cgwcPVnp6utLS0jR48GBdcsklLvccPHhQI0eOVNu2bWWz2dS6dWtJUk5OTq3GyMrKOuv7ea7va+vWrRUREeH8/PO/A7WNg+886ktAQwcAeEtYWJjatWvn/Lx8+XLZ7XYtW7ZMpaWl6tmzp15//fWz2jVv3tz55yZNmrhcMwyj1qX4C/lpv2cWS3qjX1jH2LFjNXHiREnSokWLzro+ZMgQtWrVSsuWLVNcXJwcDoe6du3qMtXpDb/0d6C2cfCdR30hcYFlGYYhPz8//fDDD7rqqqv0xhtvqEWLFrLZbF7pv2PHjsrNzVVBQYGio6Ml1WyXBurizHorwzCUlJTkcu3bb79VVlaWli1bpuuvv16S9OGHH7rVf8eOHc/6frr7ffVGHFLNjqfq6mq32wESi3NhIRUVFcrPz1d+fr7279+vSZMmqbS0VEOGDNGoUaN0ySWXaOjQodqxY4cOHz6sbdu26f7779exY8fqNN6AAQN02WWXKTk5Wf/85z+1c+dOPfbYY5LEFlS4zd/fX/v379dXX33lMl0pSU2bNlVUVJSWLl2q7Oxsvf/++5o2bZpb/U+aNEl///vfNW/ePB08eFAvvfSSNm3a5NZ31RtxSDXTUaWlpcrIyNC///1vff/99273gV8vEhdYxubNmxUbG6vY2Fj16tVLn3zyidasWaO+ffsqNDRUH3zwgRISEjR8+HB17txZ48aNU3l5eZ0rMP7+/lq/fr1KS0t19dVXa/z48c5dRcHBwd780fArYbPZzvl99PPz0+rVq7Vv3z517dpVU6dO1bPPPutW371799aSJUs0b948de/eXZs3b9bUqVPd+q56Iw6p5uF4EyZM0O23367mzZtr7ty5bveBXy/DNE2zoYMArGLnzp3q06ePsrOzddlllzV0OMAF3X333Tpw4IB27NjR0KEAtcYaF8AD69atU3h4uNq3b6/s7GxNnjxZvXv3JmlBo/Tcc89pwIABCgsL06ZNm7Ry5Uq9+OKLDR0W4BYSF8ADJSUleuihh5STk6NLLrlE/fv31/PPP9/QYQHn9PHHH2vu3LkqKSlR27ZttXDhQo0fP76hwwLcwlQRAADwGSzOBQAAPoPEBQAA+AwSFwAA4DNIXAAAgM8gcQHgltGjR2vYsGHOz3379tWUKVMuehzbtm2TYRgqLCw87z2GYWj9+vW17nPmzJnq0aOHR3EdOXJEhmEoMzPTo34AnBuJC2ABo0ePlmEYMgxDgYGBateunWbPnq3Tp0/X+9hr167Vk08+Wat7a5NsAMCF8BwXwCIGDhyotLQ0VVRU6O9//7tSUlLUpEkTPfLII2fdW1lZqcDAQK+M26xZM6/0AwC1QcUFsIigoCDFxMSoVatWuvfee9W/f3+98847kn6c3pkzZ47i4uLUsWNHSVJubq5uu+02RUZGqlmzZho6dKiOHDni7LO6ulrTpk1TZGSkoqKi9OCDD+rnj376+VRRRUWFHnroIcXHxysoKEjt2rXTihUrdOTIEfXr109Szcv6DMPQ6NGjJUkOh0Opqalq06aNQkJC1L17d7311lsu4/z9739Xhw4dFBISon79+rnEWVsPPfSQOnTooNDQULVt21YzZsxQVVXVWfe99NJLio+PV2hoqG677TYVFRW5XF++fLk6d+6s4OBgderUiafPAhcRiQtgUSEhIaqsrHR+zsjIUFZWlrZs2aKNGzeqqqpKSUlJioiI0I4dO7Rz506Fh4dr4MCBznbPP/+80tPT9fLLL+vDDz/UqVOntG7duguOe9ddd+mvf/2rFi5cqP379+ull15SeHi44uPj9fbbb0uSsrKylJeXpz//+c+SpNTUVL3yyitasmSJvvzyS02dOlV33nmntm/fLqkmwRo+fLiGDBmizMxMjR8/Xg8//LDbv5OIiAilp6frq6++0p///GctW7ZM8+fPd7knOztbb775pjZs2KDNmzfr008/1X333ee8/vrrr+vxxx/XnDlztH//fj399NOaMWOGVq5c6XY8AOrABODzkpOTzaFDh5qmaZoOh8PcsmWLGRQUZE6fPt15PTo62qyoqHC2efXVV82OHTuaDofDea6iosIMCQkx3333XdM0TTM2NtacO3eu83pVVZXZsmVL51imaZo33nijOXnyZNM0TTMrK8uUZG7ZsuWccW7dutWUZH733XfOc+Xl5WZoaKj50Ucfudw7btw4c+TIkaZpmuYjjzxidunSxeX6Qw89dFZfPyfJXLdu3XmvP/vss2bPnj2dn5944gnT39/fPHbsmPPcpk2bTD8/PzMvL880TdO87LLLzFWrVrn08+STT5qJiYmmaZrm4cOHTUnmp59+et5xAdQda1wAi9i4caPCw8NVVVUlh8Oh//qv/9LMmTOd16+44gqXdS2fffaZsrOzFRER4dJPeXm5Dh06pKKiIuXl5alXr17OawEBAfrNb35z1nTRGZmZmfL399eNN95Y67izs7P1/fffa8CAAS7nKysrdeWVV0qS9u/f7xKHJCUmJtZ6jDPeeOMNLVy4UIcOHVJpaalOnz4tm83mck9CQoIuvfRSl3EcDoeysrIUERGhQ4cOady4cbr77rud95w+fVp2u93teAC4j8QFsIh+/fpp8eLFCgwMVFxcnAICXP96h4WFuXwuLS1Vz5499frrr5/VV/PmzesUQ0hIiNttSktLJUl/+9vfXBIGqWbdjrfs2rVLo0aN0qxZs5SUlCS73a7Vq1e79VLMM7EuW7bsrETK39/fa7ECOD8SF8AiwsLC1K5du1rff9VVV+mNN95QixYtzqo6nBEbG6s9e/bohhtukFRTWdi3b5+uuuqqc95/xRVXyOFwaPv27erfv/9Z189UfKqrq53nunTpoqCgIOXk5Jy3UtO5c2fnQuMzdu/e/cs/5E989NFHatWqlR599FHnuaNHj551X05Ojo4fP664uDjnOH5+furYsaOio6MVFxenr7/+WqNGjXJrfADeweJc4Fdq1KhRuuSSSzR06FDt2LFDhw8f1rZt23T//ffr2LFjkqTJkyfrmWee0fr163XgwAHdd999F3wGS+vWrZWcnKyxY8dq/fr1zj7ffPNNSVKrVq1kGIY2btyokydPqrS0VBEREZo+fbqmTp2qlStX6tChQ/rHP/6hv/zlL84FrxMmTNDBgwf1wAMPKCsrS6tWrVJ6erpbP2/79u2Vk5Oj1atX69ChQ1q4cOE5FxoHBwcrOTlZn332mXbs2KH7779ft912m2JiYiRJs2bNUmpqqhYuXKh//etf+vzzz5WWlqZ58+a5FQ+AuiFxAX6lQkND9cEHHyghIUHDhw9X586dNW7cOJWXlzsrMP/93/+tP/3pT0pOTlZiYqIiIiJ06623XrDfxYsX6w9/+IPuu+8+derUSXfffbfKysokSZdeeqlmzZqlhx9+WNHR0Zo4caIk6cknn9SMGTOUmpqqzp07a+DAgfrb3/6mNm3aSKpZd/L2229r/fr16t69u5YsWaKnn37arZ/397//vaZOnaqJEyeqR48e+uijjzRjxoyz7mvXrp2GDx+u3/3ud7r55pvVrVs3l+3O48eP1/Lly5WWlqYrrrhCN954o9LT052xAqhfhnm+VXYAAACNDBUXAADgM0hcAACAzyBxAQAAPoPEBQAA+AwSFwAA4DNIXAAAgM8gcQEAAD6DxAUAAPgMEhcAAOAzSFwAAIDPIHEBAAA+g8QFAAD4jP8PTYM/G6GJkXcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['Benign', 'Malignant'])\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the Precision, which is the proportion of positive predictions that are actually positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision score:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the F1 score, which is the harmonic mean or precision and recall that measures the balance between them\n",
    "* Get the recall score, which os the proportion of positive samples that are correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*----------------------------*\n",
      "Recall:  0.9859154929577465\n",
      "*----------------------------*\n",
      "f1:  0.979020979020979\n",
      "*----------------------------*\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"*----------------------------*\")\n",
    "print(\"Recall: \", recall)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"*----------------------------*\")\n",
    "print(\"f1: \", f1)\n",
    "print(\"*----------------------------*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions from MLP\n",
    "\n",
    "Based on these results for the confusion matrix, I would conclude that the classification model is very accurate and has high performance on the test set.\n",
    "\n",
    "# Results analysis\n",
    "* Accuracy 0.973 this means that the model predicted correctly 97.37% of the test samples\n",
    "* Precision \n",
    "    * 0.9722 for positive (malignant) calculated by the formula TP/(TP + FP) giving a 97.22% of correctly predicted malignant samples\n",
    "    * 0.9762 for negative (benignant) calculated by the formula TN/(TN + FN) giving a 97.62% of correctly predicted benign samples\n",
    "* Recall \n",
    "    * 0.9859 Proportion of positive samples (malignant) that are correctly determined by the formula TP/(TP + FN) meaning 98.58% correct predictions\n",
    "    * 0.9535 Proportion of negative samples (benign)    that are correctly determined by the formula FN/(FN + TN) meaning 95.35% correct predictions\n",
    "* F1 score: The harmonic mean of precision and recall that measures the balance between them calculated by: 2 * (precision * recall) / (precision + recall)\n",
    "    * positive (malignant): 0.9790 which means there's a high balance between precision and recall for the malignan samples\n",
    "    * negative (benign):    0.9648 which means there's a high balance between precision and recall for the benign   samples\n",
    "\n",
    "* There's a very good overall score for the MLP approach to this dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
